# ÏùòÏïàÎÇ¥Ïö© ÏöîÏïΩÌïòÎäî ÏΩîÎìú

import sys
from pathlib import Path

# ÌòÑÏû¨ ÌååÏùºÏùò ÏÉÅÏúÑ(Î∂ÄÎ™®) ÎîîÎ†âÌÜ†Î¶¨(laws-radar)Î•º sys.pathÏóê Ï∂îÍ∞Ä (ÏÉÅÎåÄÍ≤ΩÎ°ú Î∞©Ïãù)
sys.path.append(str(Path(__file__).resolve().parent.parent))

import pandas as pd
import time
import random
import re
import signal
import atexit
from concurrent.futures import ThreadPoolExecutor
import google.generativeai as genai
from google.generativeai import types
from settings import GEOVOTE_DATA_DIR  # settings.pyÏóêÏÑú GEOVOTE_DATA_DIR ÏûÑÌè¨Ìä∏

# --- ÌôòÍ≤ΩÎ≥ÄÏàò Î∞è dotenv Ï†ÅÏö© Î∂ÄÎ∂Ñ Ï∂îÍ∞Ä ---
import os
from dotenv import load_dotenv

load_dotenv()  # .env ÌååÏùºÏóêÏÑú ÌôòÍ≤ΩÎ≥ÄÏàò Î∂àÎü¨Ïò§Í∏∞

class GracefulExiter:
    def __init__(self):
        self.exit = False
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)

    def signal_handler(self, signum, frame):
        print("\n‚ö†Ô∏è ÏïàÏ†ÑÌïú Ï¢ÖÎ£åÎ•º ÏãúÏûëÌï©ÎãàÎã§. ÌòÑÏû¨ÍπåÏßÄ Ï≤òÎ¶¨Îêú ÎÇ¥Ïö©ÏùÑ Ï†ÄÏû•Ìï©ÎãàÎã§...")
        self.exit = True

def initialize_system():
    try:
        GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
        if not GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEY ÌôòÍ≤ΩÎ≥ÄÏàòÍ∞Ä ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÏßÄ ÏïäÏäµÎãàÎã§.")
        genai.configure(api_key=GEMINI_API_KEY)
        print("‚úÖ Gemini API Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
        return genai
    except Exception as e:
        print(f"‚ùå ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {str(e)}")
        return None

def emergency_save(df, path):
    try:
        df.to_csv(str(path) + ".emergency", index=False, encoding='utf-8-sig')
        print(f"üÜò ÎπÑÏÉÅ Ï†ÄÏû• ÏôÑÎ£å: {path}.emergency")
    except Exception as e:
        print(f"‚ùå ÎπÑÏÉÅ Ï†ÄÏû• Ïã§Ìå®: {str(e)}")

def correct_spacing_and_spell(text):
    try:
        from pykospacing import Spacing
        from hanspell import spell_checker
        spacing = Spacing()
        spaced_text = spacing(text)
        spelled_text = spell_checker.check(spaced_text).checked
        return spelled_text
    except ImportError:
        return text
    except Exception:
        return text

def convert_to_sentence(summary):
    text = re.sub(r'[‚Üí¬∑|,]', '', summary).strip()
    if not re.search(r'(Ìï®|Í∞ïÌôîÌï®|Í∞úÏÑ†Ìï®|ÎßàÎ†®Ìï®|Ï§ëÎã®Ìï®|Ï∂îÏßÑÌï®|Ïã†ÏÑ§Ìï®|ÏÇ≠Ï†úÌï®|Ïöî)$', text):
        text += 'Ìï®'
    return text

def parse_gemini_response(response):
    try:
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                parts = candidate.content.parts
                if parts and hasattr(parts[0], 'text'):
                    return parts[0].text.strip()
        if hasattr(response, 'text'):
            return response.text.strip()
        if hasattr(response, 'result'):
            result = response.result
            if hasattr(result, 'candidates') and result.candidates:
                candidate = result.candidates[0]
                if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                    parts = candidate.content.parts
                    if parts and hasattr(parts[0], 'text'):
                        return parts[0].text.strip()
        if hasattr(response, '_result'):
            result = response._result
            if hasattr(result, 'candidates') and result.candidates:
                candidate = result.candidates[0]
                if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                    parts = candidate.content.parts
                    if parts and hasattr(parts[0], 'text'):
                        return parts[0].text.strip()
        response_str = str(response)
        if response_str and response_str != str(type(response)):
            return response_str.strip()
        print("üî¥ ÏùëÎãµ Íµ¨Ï°∞ Î∂ÑÏÑù:")
        print(f"ÏùëÎãµ ÌÉÄÏûÖ: {type(response)}")
        print(f"ÏùëÎãµ ÏÜçÏÑ±: {[attr for attr in dir(response) if not attr.startswith('_')]}")
        return None
    except AttributeError as e:
        print(f"üî¥ ÏÜçÏÑ± Ïò§Î•ò: {str(e)}")
        return None
    except Exception as e:
        print(f"üî¥ ÌååÏã± Ïò§Î•ò: {str(e)}")
        return None

def generate_summary(client, original_text, max_retries=5):
    if pd.isna(original_text) or not original_text.strip():
        return original_text

    for attempt in range(max_retries):
        try:
            model = client.GenerativeModel('gemini-1.5-flash-latest')
            prompt = f"""
[Î≤ïÏïà ÏöîÏïΩ Í∑úÏπô]
1. Î∞òÎìúÏãú Ìïú Î¨∏Ïû•ÏúºÎ°ú, ÌïµÏã¨ Ï°∞ÏπòÏôÄ Í∑∏ ÏõêÏù∏(Ïù¥Ïú†, Î∞∞Í≤Ω Îì±)Ïù¥ Î™®Îëê Ìè¨Ìï®ÎêòÎèÑÎ°ù Í∞ÑÍ≤∞ÌïòÍ≤å ÏöîÏïΩÌïòÏÑ∏Ïöî.
2. ÏöîÏïΩÎ¨∏ÏùÄ Ìï≠ÏÉÅ '~ÏùÑ/Î•º [ÏõêÏù∏/Î∞∞Í≤Ω/Ïù¥Ïú†]Î°ú Ïù∏Ìï¥/ÏóêÏÑú Í∏∞Ïù∏ÌïòÏó¨ ~ÏùÑ/Î•º ...Ìï®' ÎòêÎäî '~ÏùÑ/Î•º ...Ìï®'Ïùò ÌòïÌÉúÎ°ú ÎÅùÎÇòÎèÑÎ°ù ÌÜµÏùºÌïòÏÑ∏Ïöî.
3. 'Í∞úÏÑ†Ìï®', 'Í∞ïÌôîÌï®', 'Ï§ëÎã®Ìï®', 'ÎßàÎ†®Ìï®', 'Ï∂îÏßÑÌï®', 'Ïã†ÏÑ§Ìï®', 'ÏÇ≠Ï†úÌï®' Îì± Ï†ïÏ±ÖÏ†Å Ïñ¥ÎØ∏Î•º ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.
4. Î∂àÌïÑÏöîÌïú ÏàòÏãùÏñ¥, Î∞òÎ≥µ, Î∞∞Í≤ΩÏÑ§Î™Ö, 'Í¥ÄÎ†® Í∞úÏÑ† Î∞©Ïïà' Îì± ÎÑ£ÏßÄ ÎßàÏÑ∏Ïöî.
5. ÌäπÏàòÎ¨∏Ïûê(‚Üí, ¬∑, |, ,) ÏÇ¨Ïö© Í∏àÏßÄ.
6. ÏòàÏãú:
- Ïù∏ÏÇ¨ Í¥ÄÎ†® Ï†úÎèÑÎ•º Î≥µÏû°Ìïú Ï†àÏ∞®Î°ú Ïù∏Ìï¥ Í∞úÏÑ†Ìï®
- ÏßÄÏõê Ï†úÏô∏ Í∑úÏ†ïÏùÑ ÎÇ®Ïö© ÏÇ¨Î°Ä Ï¶ùÍ∞ÄÎ°ú Í∞ïÌôîÌï®
- Î∂àÌïÑÏöîÌïú ÏúÑÏõêÌöå Ïö¥ÏòÅÏùÑ Ïã§Ìö®ÏÑ± Î∂ÄÏ°±ÏúºÎ°ú Ï§ëÎã®Ìï®
- Í≥µÏÇ¨Î™Ö Î≥ÄÍ≤ΩÏùò ÌòºÎûÄÏùÑ Î∞©ÏßÄÌïòÍ∏∞ ÏúÑÌï¥ Í¥ÄÎ†® Î≤ïÏïàÏùÑ ÎßàÎ†®Ìï®

[ÏõêÎ¨∏]
{original_text}

[ÏöîÏïΩ]
"""
            response = model.generate_content(
                prompt,
                generation_config=types.GenerationConfig(
                    temperature=0.1,
                    max_output_tokens=100
                )
            )
            summary = parse_gemini_response(response)
            if not summary:
                raise ValueError("Gemini ÏùëÎãµÏóêÏÑú ÏöîÏïΩ ÌÖçÏä§Ìä∏Î•º Ï∞æÏùÑ Ïàò ÏóÜÏùå")
            final_text = convert_to_sentence(summary)
            final_text = correct_spacing_and_spell(final_text)
            final_text = re.sub(r'[‚Üí¬∑|,]', '', final_text)
            return final_text
        except Exception as e:
            err_msg = str(e)
            print(f"üî¥ ÏãúÎèÑ {attempt + 1}/{max_retries} Ïã§Ìå®: {err_msg}")
            if any(code in err_msg for code in ["503", "UNAVAILABLE", "SERVICE_UNAVAILABLE"]):
                wait = random.randint(10, 30) * (attempt + 1)
                print(f"‚ö†Ô∏è ÏÑúÎ≤Ñ Ïò§Î•ò: {wait}Ï¥à ÌõÑ Ïû¨ÏãúÎèÑ")
                time.sleep(wait)
            elif "429" in err_msg or "RATE_LIMIT" in err_msg:
                print(f"‚è≥ ÏöîÏ≤≠ ÌïúÎèÑ Ï¥àÍ≥º: 60Ï¥à ÎåÄÍ∏∞")
                time.sleep(60)
            else:
                wait = random.randint(3, 8)
                print(f"‚ö†Ô∏è ÏùºÎ∞ò Ïò§Î•ò: {wait}Ï¥à ÌõÑ Ïû¨ÏãúÎèÑ")
                time.sleep(wait)
    print(f"‚ùå ÏµúÎåÄ Ïû¨ÏãúÎèÑ ÌöüÏàò Ï¥àÍ≥º, ÏõêÎ≥∏ ÌÖçÏä§Ìä∏ Ïú†ÏßÄ")
    return original_text
# Ï∂îÍ∞Ä
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed

def generate_summaries_parallel(df, client, max_workers=5):
    results = [None] * len(df)

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_idx = {
            executor.submit(generate_summary, client, df.at[i, "content"]): i
            for i in range(len(df))
        }

        for future in tqdm(as_completed(future_to_idx), total=len(future_to_idx), desc="ÏöîÏïΩ ÏÉùÏÑ± Ï§ë"):
            idx = future_to_idx[future]
            try:
                results[idx] = future.result()
            except Exception as e:
                print(f"Ïù∏Îç±Ïä§ {idx} Ï≤òÎ¶¨ Ïã§Ìå®: {e}")
                results[idx] = df.at[idx, "content"]  # Ïã§Ìå® Ïãú ÏõêÎ≥∏ Ïú†ÏßÄ

    df["summary"] = results
    return df

# ---
def process_csv_file(client, input_path, output_path, max_workers=4, requests_per_minute=30):
    exiter = GracefulExiter()
    df = pd.read_csv(input_path, engine='python')
    print(f"üìÇ ÌååÏùº Î°úÎìú ÏôÑÎ£å: {len(df)}Í∞ú Ìñâ")
    atexit.register(emergency_save, df.copy(), output_path)
    try:
        total_rows = len(df)
        batch_size = max_workers
        interval = 60.0 / requests_per_minute * batch_size
        start_time = time.time()
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            for batch_start in range(0, total_rows, batch_size):
                if exiter.exit:
                    print("üö® ÏÇ¨Ïö©Ïûê ÏöîÏ≤≠Ïóê ÏùòÌï¥ Ï≤òÎ¶¨ Ï§ëÎã®")
                    executor.shutdown(wait=False)
                    break
                batch_end = min(batch_start + batch_size, total_rows)
                futures = [(idx, executor.submit(generate_summary, client, df.at[idx, 'content']))
                          for idx in range(batch_start, batch_end)]
                for idx, future in futures:
                    if exiter.exit:
                        break
                    try:
                        result = future.result(timeout=120)
                        df.at[idx, 'content'] = result
                    except Exception as e:
                        print(f"‚ö†Ô∏è Ìñâ {idx} Ï≤òÎ¶¨ Ïã§Ìå®: {str(e)}")
                        df.at[idx, 'content'] = f"Ïò§Î•ò: {str(e)}"
                processed = min(batch_end, total_rows)
                print(f"ÏßÑÌñâÎ•†: {processed}/{total_rows} ({processed/total_rows*100:.1f}%)")
                if batch_end % 20 == 0:
                    df.to_csv(output_path, index=False, encoding='utf-8-sig')
                    print(f"üíæ ÏûÑÏãú Ï†ÄÏû• ÏôÑÎ£å: {batch_end}Ìñâ")
                elapsed = time.time() - start_time
                sleep_time = max(interval - elapsed, 0)
                if sleep_time > 0:
                    time.sleep(sleep_time)
                start_time = time.time()
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"\n‚úÖ ÏµúÏ¢Ö Ï†ÄÏû• ÏôÑÎ£å: {output_path}")
    except Exception as e:
        print(f"‚ùå CSV Ï≤òÎ¶¨ Ïò§Î•ò: {str(e)}")
    finally:
        atexit.unregister(emergency_save)
        emergency_save(df, output_path)

if __name__ == "__main__":
    INPUT_PATH = GEOVOTE_DATA_DIR / "bill_filtered_final.csv"
    OUTPUT_PATH = GEOVOTE_DATA_DIR / "summary_of_content.csv"
    gemini_client = initialize_system()
    if gemini_client:
        process_csv_file(
            gemini_client,
            INPUT_PATH,
            OUTPUT_PATH,
            max_workers=4,
            requests_per_minute=30
        )
